{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6장 데이터 로딩과 저장, 파일 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(12345)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "pd.options.display.max_colwidth = 75\n",
    "pd.options.display.max_columns = 20\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.rcParams[\"font.family\"] = 'Malgun Gothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. csv 텍스트 데이터\n",
    "## 1.1 csv파일 읽기\n",
    "* 판다스에서 CSV 파일을 읽기: pd.read_csv(path, encoding = 'utf-8') 함수를 사용\n",
    "    * path 인수 : 파일시스템에서의 위치, URL, 파일객체를 나타내는 문자열\n",
    "    * encoding 인수 - 유니코드 인코딩 종류을 지정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) header(컬럼명)가 있는 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex1.csv\n",
    "\n",
    "df = pd.read_csv(\"examples/ex1.csv\", encoding= \"utf-8\") # csv file -> DataFrame으로 반환\n",
    "type(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2) header가 없는 파일 : 컬럼을 지정\n",
    "        * names 인수 - 열 이름 리스트\n",
    "        * header 인수 - 헤더가 없을 경우 None으로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex2.csv\n",
    "\n",
    "names = [\"a\", \"b\", \"c\", \"d\", \"message\"]\n",
    "data = pd.read_csv(\"examples/ex2.csv\", names=names) #names 인수 - 데이터프레임의 컬럼명 지정\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3) 계층적 색인 지정하기\n",
    "        * index_col 인수 - 색인으로 사용할 열 번호나 이름, 계층적 색인을 지정할 경우 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/csv_mindex.csv\n",
    "parsed = pd.read_csv(\"examples/csv_mindex.csv\",\n",
    "                     index_col=[\"key1\", \"key2\"])\n",
    "parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4) 여러 개의 공백(spacebar)으로 필드를 구분한 파일 : txt포맷\n",
    "        * sep 인수 - 필드(컬럼)을 구분하기 위해 사용할 정규 표현식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex3.txt\n",
    "result = pd.read_csv(\"examples/ex3.txt\", sep=\"\\s+\") # 정규표현식 : \" \\s+  \"\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5) 주석을 갖고 있는 파일\n",
    "        * skiprows 인수 - 파일의 시작부터 무시할 행 수 또는 무시할 행 번호가 담긴 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex4.csv\n",
    "pd.read_csv(\"examples/ex4.csv\", skiprows=[0, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6) 누락된 값이 있는 파일 : 비어 있는 문자열, NA, NULL을 NaN으로 출력 \n",
    "        * na_values 인수 - NA 값으로 처리할 값들의 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex5.csv\n",
    "# na_values 인수을 사용하지 않은 경우\n",
    "result = pd.read_csv(\"examples/ex5.csv\")\n",
    "result\n",
    "# 1) 누락된 값을 확인 : isna(), isnull(), notna(), notnull()\n",
    "pd.isna(result)\n",
    "\n",
    "# 2) na_values -> 컬럼별 문자열 집합을 받아서 누락된 값 처리\n",
    "sentinels = {\"message\": [\"foo\", \"NA\"], \"something\": [\"two\"]}\n",
    "result = pd.read_csv(\"examples/ex5.csv\", na_values=sentinels)\n",
    "print(result)\n",
    "result.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7) 텍스트 파일 조금씩 \n",
    "        * nrows 인수 - 파일의 첫 일부만 읽어올 때 처음 몇 줄을 읽을 것인지 지정 \n",
    "        * chunksize 인수 - TextParser 객체에서 사용할 한 번에 익을 파일의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 10\n",
    "!cat examples/ex6.csv\n",
    "# result = pd.read_csv(\"examples/ex6.csv\")\n",
    "# result\n",
    "# result = pd.read_csv(\"examples/ex6.csv\", nrows=5)\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제]  ex6.csv 파일을 순회하면서 \"key\"열의 값을 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = pd.read_csv(\"examples/ex6.csv\", chunksize=1000)\n",
    "chunker\n",
    "# type(chunker)\n",
    "#1) 리스트의 시리즈 생성 - 청크 다위로 key\"열의 값 저장\n",
    "tot = pd.Series([], dtype='int64')\n",
    "type(tot)\n",
    "#2) 반복 처리 \n",
    "\n",
    "for piece in chunker:\n",
    "    # print(type(piece[\"key\"]))\n",
    "    # print(piece[\"key\"].value_counts())\n",
    "    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n",
    "\n",
    "tot = tot.sort_values(ascending=False)\n",
    "tot\n",
    "tot[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note\n",
    "from pandas import Series\n",
    "tot = pd.Series([], dtype='int64')\n",
    "# type(tot) # Series\n",
    "\n",
    "for piece in range(3):\n",
    "    tot = tot.add(Series([1,2,3]), fill_value = 10) # tot + Series([1,2,3]\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. csv 텍스트 파일 저장하기\n",
    "* 판다스에서 CSV 파일을 저장하기: df.to_csv(path, encoding = 'utf-8') 함수를 사용\n",
    "    * path 인수 : 파일시스템에서의 위치, URL, 파일객체를 나타내는 문자열\n",
    "    * encoding 인수 - 유니코드 인코딩 종류을 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat examples/ex5.csv\n",
    "# 1) 준비 : DataFrame\n",
    "data = pd.read_csv(\"examples/ex5.csv\") #-> DataFrame 반환\n",
    "# 2. 조작 : DataFrame에서 인덱싱해서 필요한 데이터 추출-> DataFrame\n",
    "data1 = data[['a','b','d']]\n",
    "print(data1)\n",
    "# # 3. data1 -> csv 파일로 저장\n",
    "data1.to_csv(\"examples/out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(\"examples/out.csv\", sep=\"|\") # 구분자 사용\n",
    "data1.to_csv(\"examples/out.csv\", na_rep = \"NULL\") #누락된 값을 원하는 값으로 지정\n",
    "# data.to_csv(\"examples/out.csv\", index=False, header=False)\n",
    "data1.to_csv(\"examples/out.csv\", index=False, columns=[\"a\", \"b\", \"d\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. JSON  데이터\n",
    "* JSON(JavaScript Object Notation)은 텍스트 데이터를 저장하고 전송하기 위한 일반적인 형식\n",
    "* 주로 웹에서 데이터를 전송하거나 저장하는 데 사용\n",
    "* JSON 파일은 일반적으로 텍스트 형식으로 작성되며, 사람과 기계 모두 이해하기 쉽다.\n",
    "* JSON 파일은 키-값 쌍의 모음으로 구성\n",
    "  * 키-값 쌍은 객체(object)라고도 하며, 중괄호 {} 로 묶는다.\n",
    "  * 배열(array)은 대괄호 [] 안에 값의 목록을 나열하여 정의."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 JSON 데이터 읽기/저장\n",
    "    * pandas의 to_json() -> 데이터프레임을 JSON 파일로 저장\n",
    "    * read_json() -> JSON 파일에서 데이터프레임을 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제]  pandas의 to_json() 및 read_json() 메서드를 사용하여 데이터프레임을 JSON 파일로 저장하고 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pandas 라이브러리 임포트\n",
    "import pandas as pd\n",
    "\n",
    "# 2. JSON 파일로 저장할 데이터프레임 생성\n",
    "data = {\n",
    "    \"name\": [\"John\", \"Alice\", \"Bob\"],\n",
    "    \"age\": [30, 25, 35],\n",
    "    \"city\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 3. 데이터프레임을 JSON 파일로 저장\n",
    "df.to_json(\"examples/data.json\")\n",
    "\n",
    "# # JSON 파일을 읽어와 데이터프레임으로 변환\n",
    "df_read = pd.read_json(\"examples/data.json\")\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame from JSON file:\")\n",
    "print(df_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. HTML 데이터\n",
    "## 3.1 웹 스크래핑 - read_html()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read_html() - html 문서 내 테이블 데이터 읽어 테이블 구조의 모든 데이터를 데이터프레임으로 저장해서 반환\n",
    "    * https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 개발자 도구 사용 방법\n",
    "    * #s_content > div.section > ul > li:nth-child(1) > dl > dt > a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [예제] 미국 예금 보험 공사에서 부도 은행을 보여주는 HTML 문서 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "tables = pd.read_html(\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\")\n",
    "type(tables)\n",
    "len(tables) # 1\n",
    "failures = tables[0]\n",
    "failures\n",
    "type(failures)\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이터프레임 가공\n",
    "# 1) 컬럼명 수정하기\n",
    "failures.columns\n",
    "failures.columns = ['BankNameBank', 'CityCity', 'StateSt', 'CertCert',\n",
    "       'AcquiringInstitutionAI', 'ClosingDate', 'FundFund']\n",
    "failures.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 데이터 변환 : 문자열 object -> datetime\n",
    "close_timestamps = pd.to_datetime(failures[\"ClosingDate\"]) # 컬럼 인덱싱\n",
    "close_timestamps\n",
    "#3) 년도별 부도난 은행의 개수 추출\n",
    "close_timestamps.dt.year.value_counts() # Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습] : 네이버 주식 데이터 가져오기 - read_html()\n",
    "* https://www.naver.com/ -> 증권 -> 국내증시 -> 시가총액\n",
    "    * https://finance.naver.com/sise/sise_market_sum.naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install html5lib  lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 'euc-kr' 또는 'cp949'로 인코딩 설정하여 페이지 읽기 시도\n",
    "df_list = pd.read_html(\"https://finance.naver.com/sise/sise_market_sum.naver\",encoding = 'cp949')\n",
    "type(df_list)\n",
    "len(df_list)\n",
    "type(df_list[1])\n",
    "# 데이터프레임 확인\n",
    "for df in df_list:\n",
    "    print(\"\\n\",df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 가공- 종목명에 NaN이 읶는 행은 제거\n",
    "df = df_list[1] # 컬럼 인덱싱\n",
    "df.head(10)\n",
    "#boolean indexing \n",
    "df['종목명'] # 1. 컬럼 추출 -Series\n",
    "df['종목명'].notnull() #2. 조건 색인\n",
    "data = df[df['종목명'].notnull()] # 3. 조건색인으로 인덱싱하기\n",
    "data\n",
    "data.head()\n",
    "# 가공한 데이터프레임을 파일로 저장\n",
    "data.to_csv(\"examples/Naver_kospi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 웹 스크래핑 - requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 웹 페이지 정보 가져오기 - requests 패키지 이용\n",
    "  * requests.get()\n",
    "  * requests.get().status_code\n",
    "  * requests.get().text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제] 타겟 사이트의 json 구조로 저장된 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. requests 모듈 임포트하기\n",
    "import requests\n",
    "import pandas as pd\n",
    "#2. url 가져오기\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "#pd.read_html(url)\n",
    "# 3.페이지을 가져오기\n",
    "resp = requests.get(url)\n",
    "type(resp)\n",
    "resp.status_code #200\n",
    "resp.text # 데이터 가져오기\n",
    "type(resp.text)\n",
    "\n",
    "# 4. json 내용을 딕셔너리로 변환\n",
    "data = resp.json() # json의 내용을 딕셔너리 형태로 변환한 객체을 반환\n",
    "type(data)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] 네이버 블로그의 키워드 관련 검색 결과 텍스트 데이터 가져오기 - requests 모듈 사용시 한계점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# url = \"https://section.blog.naver.com/Search/Post.naver?\\\n",
    "# pageNo=1&rangeType=ALL&orderBy=sim&keyword=%ED%8C%8C%EC%9D%B4%EC%8D%AC\"\n",
    "\n",
    "params = {\n",
    "    'pageNo' : 1,\n",
    "    'rangeType' : 'ALL',\n",
    "    'orderBy' : 'sim',\n",
    "    'keyword' : '파이썬'\n",
    "}\n",
    "\n",
    "#pd.read_html(url)\n",
    "response = requests.get('https://section.blog.naver.com/Search/Post.naver?', params=params)\n",
    "\n",
    "print(response.status_code) # HTTP GET 방식으로 URL 파라미터 값 전달\n",
    "print(response.url) # status_code 는 응답코드\n",
    "print(response.text) # text에는 HTML 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 웹 스크래핑 - beautifulsoup (4/10일 비대면 수업)\n",
    "* 웹 페이지 정보 추출하기 - beautifulsoup 사용법 \n",
    "  * soup.select_one()\n",
    "  * soup.select()\n",
    "  * get_text()\n",
    "* 개발자 도구 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] 네이버 지식iN의 검색어 관련 검색 결과 제목 가져오기\n",
    "* 타겟 웹 사이트 : https://kin.naver.com/search/list.naver?query=%ED%8C%8C%EC%9D%B4%EC%8D%AC\n",
    "* soup.select_one()\n",
    "* soup.select()\n",
    "* 개발자 도구 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. 단계 웹 사이트 url\n",
    "url = 'https://kin.naver.com/search/list.naver?query=%ED%8C%8C%EC%9D%B4%EC%8D%AC'\n",
    "\n",
    "# 2. 웹 페이지 로딩\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # 웹 페이지 확인\n",
    "    html = response.text\n",
    "    # html -> beautifulsoup 객체로 변환 : 원하는 데이터를 설계 추출\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 5. 데이터 추출 : 제목 한개 선택하여 덱스트 가져오기\n",
    "    \n",
    "    title = soup.select_one('#s_content > div.section > ul > li:nth-child(1) > dl > dt > a')\n",
    "    print(title)\n",
    "    print(title.get_text())\n",
    "\n",
    "    # 6. 데이터 추출 : 제목 여러 개 선택하여 텍스트 리스트 가져오기\n",
    "    titles = soup.select('#s_content > div.section > ul > li:nth-child(n) > dl > dt > a')\n",
    "    print(titles)\n",
    "\n",
    "    # 7. 제목의 텍스트를 반복적으로 적용하여 가져오기\n",
    "    for title in titles:\n",
    "        print(title.get_text())\n",
    "else : \n",
    "    print(response.status_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 웹 스크래핑 - Selenium을 이용하여 사이트 자동화하기\n",
    "* selenium 사용법\n",
    "  1. 시스템의 OS 및 Chrome 브라우저의 버전 확인\n",
    "  2. Chrome 드라이버 다운로드 및 설치\n",
    "  3. 크롬 드라이버을 프로젝트 폴더에 저장 - 크롬 드라이버의 설치 경로\n",
    "     * from selenium import webdriver\n",
    "     * driver = webdriver.Chrome()\n",
    "* 동적으로 웹 페이지 정보 추출하기\n",
    "     * driver.get(\"웹주소\") \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [예제] Selenium을 이용하여 자동으로 타겟 웹 사이트 실행하기\n",
    "* 타겟 사이트 : https://www.google.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://selenium-python.readthedocs.io/\n",
    "from selenium import webdriver\n",
    "# Chrome 브라우저 실행\n",
    "driver = webdriver.Chrome()\n",
    "# 웹페이지 열기\n",
    "url = \"https://www.google.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] Selenium을 이용하여 자동으로 타겟 웹 사이트 실행하기/검색하기/검색 결과 출력하기\n",
    "* 타겟 사이트: https://www.google.com\n",
    "* driver.find_element()\n",
    "* send_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "# 1. Chrome 브라우저 실행\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 2. 타겟 Google 홈페이지 열기\n",
    "url = \"https://www.google.com\"\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지가 완전히 로드될 때까지 2초 대기\n",
    "time.sleep(2)\n",
    "\n",
    "# 4. 검색 기능 - 검색창 -> 검색어 입력 -> 엔터 키로 클릭 처리\n",
    "try:\n",
    "    # 검색 상자 요소 찾기\n",
    "    search_box = driver.find_element(By.NAME, \"q\") \n",
    "\n",
    "    # 검색어 입력\n",
    "    search_query = \"OpenAI\"\n",
    "    search_box.send_keys(search_query)\n",
    "\n",
    "    # Enter 키를 눌러 검색 수행\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    # 검색 결과가 로드될 때까지 5초 대기\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 5. 검색에 관련된 결과 추출\n",
    "    search_results = driver.find_elements(By.CSS_SELECTOR, \"div.g\") \n",
    "    \n",
    "    # 검색 결과의 제목과 URL 인쇄\n",
    "    for result in search_results:\n",
    "        title = result.find_element(By.CSS_SELECTOR, \"h3\").text\n",
    "        url = result.find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "        print(\"제목:\", title)\n",
    "        print(\"URL:\", url)\n",
    "        print()\n",
    "\n",
    "    # search_results = driver.find_elements(By.CSS_SELECTOR, \"div.g\") \n",
    "    # title = search_results[0].find_element(By.CSS_SELECTOR, \"h3\").text\n",
    "    # url = search_results[0].find_element(By.CSS_SELECTOR, \"a\").get_attribute(\"href\")\n",
    "    # print(\"제목:\", title)\n",
    "    # print(\"URL:\", url)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"오류가 발생했습니다:\", e)\n",
    "\n",
    "finally:\n",
    "    # 브라우저 창 닫기\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [문제] Selenium을 이용하여 네이버 증권 웹페이지 열기/ 삼성전자 일별 시세 HTML가져오기/ 10페이지 내역 테이블 데이터 찾기/검색 결과를 데이터프레임으로 변환/저장하기\n",
    "* 타겟 사이트: https://finance.naver.com/item/sise.naver?code=005930* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 크롬 드라이버 실행\n",
    "driver= webdriver.Chrome()\n",
    "\n",
    "# 2페이지 로딩 시간\n",
    "time.sleep(2)\n",
    "\n",
    "# 3. 크롤링 사이트 : 삼성전자의 일별 시세 페이지 URL 찾기\n",
    "samsung_url =\"https://finance.naver.com/item/sise_day.naver?code=005930&page=\"\n",
    "\n",
    "# 4. 첫 페이지부터 10 페이지까지 데이블 담기\n",
    "samsung_daily_kospi = []\n",
    "for num in range(1,3):\n",
    "    full_url = samsung_url + str(num)\n",
    "    # 페이지 요청\n",
    "    driver.get(full_url)\n",
    "    \n",
    "    try:\n",
    "        # 4-2. 페이지의 HTML 가져오기\n",
    "        html = driver.page_source\n",
    "        df = pd.read_html(html)\n",
    "        # 4-3. 결속치 처리 - 조건 색인을 이용한 불리언 인덱싱\n",
    "        ## 조건 새인 인덱싱\n",
    "        cond = df[0]['날짜'].notnull()\n",
    "        samsung_day = df[0][cond]\n",
    "        # 리스트에 담기\n",
    "        samsung_daily_kospi.append(samsung_day)       \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Network Error\",e)\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "print(samsung_daily_kospi)\n",
    "samsung_daily_kospi_all = pd.concat(samsung_daily_kospi)\n",
    "samsung_daily_kospi_all.to_csv(\"examples/samsung_daily_kospi_2024_04_10.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
